{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      destination                            origin    1990    1995   2000  \\\n",
      "6557      burundi                           belgium     642     621    475   \n",
      "6558      burundi  democratic republic of the congo   36654   41447  37951   \n",
      "6559      burundi                            france     321     310    237   \n",
      "6560      burundi                             kenya     186     216    202   \n",
      "6561      burundi                            rwanda  221943  160197  66415   \n",
      "...           ...                               ...     ...     ...    ...   \n",
      "35542     vanuatu                           england     239     152     95   \n",
      "35543     vanuatu                              fiji     166     146    129   \n",
      "35544     vanuatu                     new caledonia     163     161    146   \n",
      "35546     vanuatu                   solomon islands      83      65     51   \n",
      "35547     vanuatu                  papua new guinea      50      50     50   \n",
      "\n",
      "        2005    2010    2015    2020  1990.1  ...  2010.1  2015.1  2020.1  \\\n",
      "6557     466     497     605     718     315  ...     236     288     343   \n",
      "6558   99099  147611  175768  199585   17963  ...   75099   89489  101757   \n",
      "6559     232     248     302     358     157  ...     119     145     174   \n",
      "6560     502     847    1032    1226     104  ...     477     582     693   \n",
      "6561   61104   54794   64363   76567  108772  ...   24786   29140   34728   \n",
      "...      ...     ...     ...     ...     ...  ...     ...     ...     ...   \n",
      "35542    100     107     113     115     138  ...      54      57      58   \n",
      "35543    176     216     230     235      83  ...     108     115     118   \n",
      "35544    197     242     257     262      66  ...     121     129     132   \n",
      "35546     75     113     120     122      39  ...      57      61      62   \n",
      "35547     56      63      67      68      16  ...      32      34      35   \n",
      "\n",
      "       1990.2  1995.2  2000.2  2005.2  2010.2  2015.2  2020.2  \n",
      "6557      327     318     244     242     261     317     375  \n",
      "6558    18691   21295   19500   49131   72512   86279   97828  \n",
      "6559      164     159     121     120     129     157     184  \n",
      "6560       82      94      87     219     370     450     533  \n",
      "6561   113171   82134   34127   32291   30008   35223   41839  \n",
      "...       ...     ...     ...     ...     ...     ...     ...  \n",
      "35542     101      72      47      53      53      56      57  \n",
      "35543      83      69      64      90     108     115     117  \n",
      "35544      97      76      72      98     121     128     130  \n",
      "35546      44      30      25      37      56      59      60  \n",
      "35547      34      23      24      28      31      33      33  \n",
      "\n",
      "[7772 rows x 23 columns]\n",
      "Number of unique destinations: 169\n",
      "Unique destinations: ['afghanistan', 'albania', 'algeria', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bangladesh', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'democratic republic of the congo', 'denmark', 'djibouti', 'dominican republic', 'east timor', 'ecuador', 'egypt', 'el salvador', 'england', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'falkland islands', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'greenland', 'guatemala', 'guinea', 'guinea bissau', 'guyana', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'ivory coast', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'laos', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'lithuania', 'luxembourg', 'macedonia', 'madagascar', 'malawi', 'malaysia', 'mali', 'mauritania', 'mexico', 'moldova', 'mongolia', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new caledonia', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'puerto rico', 'qatar', 'republic of serbia', 'republic of the congo', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'sierra leone', 'slovakia', 'slovenia', 'solomon islands', 'somalia', 'south africa', 'south korea', 'spain', 'sri lanka', 'sudan', 'suriname', 'swaziland', 'sweden', 'switzerland', 'syria', 'tajikistan', 'thailand', 'the bahamas', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united republic of tanzania', 'uruguay', 'usa', 'uzbekistan', 'vanuatu', 'venezuela', 'vietnam', 'west bank', 'western sahara', 'yemen', 'zambia', 'zimbabwe']\n",
      "\n",
      "Number of unique origins: 171\n",
      "Unique origins: ['afghanistan', 'albania', 'algeria', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bangladesh', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'democratic republic of the congo', 'denmark', 'djibouti', 'dominican republic', 'east timor', 'ecuador', 'egypt', 'el salvador', 'england', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'falkland islands', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'greenland', 'guatemala', 'guinea', 'guinea bissau', 'guyana', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'ivory coast', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'laos', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'lithuania', 'luxembourg', 'macedonia', 'madagascar', 'malawi', 'malaysia', 'mali', 'mauritania', 'mexico', 'moldova', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new caledonia', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'puerto rico', 'qatar', 'republic of serbia', 'republic of the congo', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'sierra leone', 'slovakia', 'slovenia', 'solomon islands', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'suriname', 'swaziland', 'sweden', 'switzerland', 'syria', 'tajikistan', 'thailand', 'the bahamas', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united republic of tanzania', 'uruguay', 'usa', 'uzbekistan', 'vanuatu', 'venezuela', 'vietnam', 'west bank', 'western sahara', 'yemen', 'zambia', 'zimbabwe']\n",
      "Non-matching GeoJSON countries (5): ['french southern and antarctic lands', 'kosovo', 'northern cyprus', 'somaliland', 'taiwan']\n"
     ]
    }
   ],
   "source": [
    "def process_excel_with_geojson(excel_path, sheet_name, geojson_path):\n",
    "    \"\"\"\n",
    "    Processes an Excel file to align its data with a GeoJSON file and filter matches.\n",
    "\n",
    "    Parameters:\n",
    "        excel_path (str): Path to the Excel file.\n",
    "        sheet_name (str): Name of the sheet to read from the Excel file.\n",
    "        geojson_path (str): Path to the GeoJSON file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: The processed and filtered DataFrame.\n",
    "            - list: Non-matching GeoJSON countries.\n",
    "    \"\"\"\n",
    "    # Step 1: Load GeoJSON and extract country names\n",
    "    geo_data = gpd.read_file(geojson_path)\n",
    "    geojson_countries = [country.strip().lower() for country in geo_data['name'].tolist()]\n",
    "\n",
    "    # Step 2: Load the specific sheet from Excel and process starting from row 11\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name, skiprows=10)\n",
    "\n",
    "    # Step 3: Keep and rename relevant columns\n",
    "    columns_to_keep = {\n",
    "        'Region, development group, country or area of destination': 'destination',\n",
    "        'Region, development group, country or area of origin': 'origin',\n",
    "        1990: '1990',\n",
    "        1995: '1995',\n",
    "        2000: '2000',\n",
    "        2005: '2005',\n",
    "        2010: '2010',\n",
    "        2015: '2015',\n",
    "        2020: '2020',\n",
    "        '1990.1': '1990.1',\n",
    "        '1995.1': '1995.1',\n",
    "        '2000.1': '2000.1',\n",
    "        '2005.1': '2005.1',\n",
    "        '2010.1': '2010.1',\n",
    "        '2015.1': '2015.1',\n",
    "        '2020.1': '2020.1',\n",
    "        '1990.2': '1990.2',\n",
    "        '1995.2': '1995.2',\n",
    "        '2000.2': '2000.2',\n",
    "        '2005.2': '2005.2',\n",
    "        '2010.2': '2010.2',\n",
    "        '2015.2': '2015.2',\n",
    "        '2020.2': '2020.2',\n",
    "    }\n",
    "    df = df[list(columns_to_keep.keys())].rename(columns=columns_to_keep)\n",
    "\n",
    "    # Step 4: Remove rows with NaN or 0 values in year columns\n",
    "    year_columns = [\n",
    "        '1990', '1995', '2000', '2005', '2010', '2015', '2020',\n",
    "        '1990.1', '1995.1', '2000.1', '2005.1', '2010.1', '2015.1', '2020.1',\n",
    "        '1990.2', '1995.2', '2000.2', '2005.2', '2010.2', '2015.2', '2020.2'\n",
    "    ]\n",
    "    df = df.dropna(subset=year_columns)\n",
    "    df = df[~(df[year_columns] == 0).any(axis=1)]\n",
    "\n",
    "    # Step 5: Align names in the DataFrame with GeoJSON using equivalences\n",
    "    equivalences = {\n",
    "        \"   Australia*\": \"australia\",\n",
    "        \"   Azerbaijan*\": \"azerbaijan\",\n",
    "        \"   Bahamas\": \"the bahamas\",\n",
    "        \"   Bolivia (Plurinational State of)\": \"bolivia\",\n",
    "        \"   Brunei Darussalam\": \"brunei\",\n",
    "        \"   China*\": \"china\",\n",
    "        \"   China, Taiwan Province of China*\": \"taiwan\",\n",
    "        \"   Congo\": \"republic of the congo\",\n",
    "        \"   Côte d'Ivoire\": \"ivory coast\",\n",
    "        \"   Cyprus*\": \"cyprus\",\n",
    "        \"   Czechia\": \"czech republic\",\n",
    "        \"   Dem. People's Republic of Korea\": \"north korea\",\n",
    "        \"   Democratic Republic of the Congo\": \"democratic republic of the congo\",\n",
    "        \"   Denmark*\": \"denmark\",\n",
    "        \"   Eswatini\": \"swaziland\",\n",
    "        \"   Falkland Islands (Malvinas)*\": \"falkland islands\",\n",
    "        \"   Finland*\": \"finland\",\n",
    "        \"   France*\": \"france\",\n",
    "        \"   French Southern and Antarctic Lands\": \"french southern and antarctic lands\",\n",
    "        \"   Georgia*\": \"georgia\",\n",
    "        \"   Greenland*\": \"greenland\",\n",
    "        \"   Guinea-Bissau\": \"guinea bissau\",\n",
    "        \"   Iran (Islamic Republic of)\": \"iran\",\n",
    "        \"   Kosovo\": \"kosovo\",\n",
    "        \"   Lao People's Democratic Republic\": \"laos\",\n",
    "        \"   Malaysia*\": \"malaysia\",\n",
    "        \"   Netherlands*\": \"netherlands\",\n",
    "        \"   New Caledonia*\": \"new caledonia\",\n",
    "        \"   New Zealand*\": \"new zealand\",\n",
    "        \"   North Macedonia\": \"macedonia\",\n",
    "        \"   Northern Cyprus\": \"northern cyprus\",\n",
    "        \"   Norway*\": \"norway\",\n",
    "        \"   Puerto Rico*\": \"puerto rico\",\n",
    "        \"   Republic of Korea\": \"south korea\",\n",
    "        \"   Republic of Moldova*\": \"moldova\",\n",
    "        \"   Russian Federation\": \"russia\",\n",
    "        \"   Serbia*\": \"republic of serbia\",\n",
    "        \"   Somalia\": \"somalia\",\n",
    "        \"   Spain*\": \"spain\",\n",
    "        \"   State of Palestine*\": \"west bank\",\n",
    "        \"   Syrian Arab Republic\": \"syria\",\n",
    "        \"   The Bahamas\": \"the bahamas\",\n",
    "        \"   Timor-Leste\": \"east timor\",\n",
    "        \"   Ukraine*\": \"ukraine\",\n",
    "        \"   United Kingdom*\": \"england\",\n",
    "        \"   United Republic of Tanzania*\": \"united republic of tanzania\",\n",
    "        \"   United States of America*\": \"usa\",\n",
    "        \"   Venezuela (Bolivarian Republic of)\": \"venezuela\",\n",
    "        \"   Viet Nam\": \"vietnam\",\n",
    "    }\n",
    "\n",
    "\n",
    "    df['destination'] = df['destination'].replace(equivalences).str.strip().str.lower()\n",
    "    df['origin'] = df['origin'].replace(equivalences).str.strip().str.lower()\n",
    "\n",
    "    # Step 6: Find non-matching GeoJSON countries before filtering\n",
    "    all_countries_in_df = set(df['destination'].unique()) | set(df['origin'].unique())\n",
    "    non_matching_geojson_countries = [country for country in geojson_countries if country not in all_countries_in_df]\n",
    "\n",
    "    # Step 7: Filter rows where destination and origin match GeoJSON countries\n",
    "    df_filtered = df[\n",
    "        (df['destination'].isin(geojson_countries)) &\n",
    "        (df['origin'].isin(geojson_countries))\n",
    "    ]\n",
    "\n",
    "    return df_filtered, non_matching_geojson_countries\n",
    "\n",
    "# Example Usage\n",
    "excel_path = 'undesa_pd_2020_ims_stock_by_sex_destination_and_origin.xlsx'\n",
    "sheet_name = 'Table 1'\n",
    "geojson_path = '/Users/magdalenabarros/InteractiveViz/data/world.geojson'\n",
    "\n",
    "processed_df, non_matching_geojson = process_excel_with_geojson(excel_path, sheet_name, geojson_path)\n",
    "\n",
    "# Display the processed DataFrame\n",
    "print(processed_df)\n",
    "# Get unique destinations and origins from the filtered DataFrame\n",
    "unique_destinations = processed_df['destination'].unique()\n",
    "unique_origins = processed_df['origin'].unique()\n",
    "\n",
    "# Count how many unique destinations and origins exist\n",
    "num_unique_destinations = len(unique_destinations)\n",
    "num_unique_origins = len(unique_origins)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of unique destinations: {num_unique_destinations}\")\n",
    "print(f\"Unique destinations: {sorted(unique_destinations)}\\n\")\n",
    "\n",
    "print(f\"Number of unique origins: {num_unique_origins}\")\n",
    "print(f\"Unique origins: {sorted(unique_origins)}\")\n",
    "\n",
    "\n",
    "# Display non-matching GeoJSON countries\n",
    "print(f\"Non-matching GeoJSON countries ({len(non_matching_geojson)}): {sorted(non_matching_geojson)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Country  Year  Migration  Immigration\n",
      "0     afghanistan  1990    7679357        50671\n",
      "1     afghanistan  1995    4346546        55794\n",
      "2     afghanistan  2000    4749865        60918\n",
      "3     afghanistan  2005    4113962        67045\n",
      "4     afghanistan  2010    5263310        73174\n",
      "...           ...   ...        ...          ...\n",
      "1192     zimbabwe  2000     351911       361947\n",
      "1193     zimbabwe  2005     500684       319910\n",
      "1194     zimbabwe  2010     754430       286642\n",
      "1195     zimbabwe  2015    1166808       288208\n",
      "1196     zimbabwe  2020    1242889       299407\n",
      "\n",
      "[1197 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def analyze_migration_data(processed_df):\n",
    "    \"\"\"\n",
    "    Analyzes migration data for total migration (by origin) and immigration (by destination).\n",
    "\n",
    "    Parameters:\n",
    "        processed_df (pd.DataFrame): The filtered migration DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Aggregated total migration (by origin) and immigration (by destination) by year.\n",
    "    \"\"\"\n",
    "    # Step 1: Melt the DataFrame to make it long-format (Year, Value)\n",
    "    year_columns = ['1990', '1995', '2000', '2005', '2010', '2015', '2020']\n",
    "    melted_df = processed_df.melt(\n",
    "        id_vars=['origin', 'destination'],\n",
    "        value_vars=year_columns,\n",
    "        var_name='Year',\n",
    "        value_name='Migration'\n",
    "    )\n",
    "\n",
    "    # Step 2: Group by origin and year to calculate total migration\n",
    "    total_by_origin_year = melted_df.groupby(['origin', 'Year'])['Migration'].sum().reset_index()\n",
    "    total_by_origin_year = total_by_origin_year.rename(columns={'origin': 'Country', 'Migration': 'Migration'})\n",
    "\n",
    "    # Step 3: Group by destination and year to calculate total immigration\n",
    "    total_by_destination_year = melted_df.groupby(['destination', 'Year'])['Migration'].sum().reset_index()\n",
    "    total_by_destination_year = total_by_destination_year.rename(columns={'destination': 'Country', 'Migration': 'Immigration'})\n",
    "\n",
    "    # Step 4: Merge the two results on Country and Year\n",
    "    combined_data = pd.merge(\n",
    "        total_by_origin_year,\n",
    "        total_by_destination_year,\n",
    "        on=['Country', 'Year'],\n",
    "        how='outer'\n",
    "    ).fillna(0)  # Fill missing values with 0\n",
    "    \n",
    "    # Step 5: Ensure Migration and Immigration columns are integers\n",
    "    combined_data['Migration'] = combined_data['Migration'].astype(int)\n",
    "    combined_data['Immigration'] = combined_data['Immigration'].astype(int)\n",
    "\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Analyze the migration data\n",
    "combined_data = analyze_migration_data(processed_df)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(combined_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Year\": 1990,\n",
      "        \"Population\": 12045664,\n",
      "        \"Population dots\": 12,\n",
      "        \"Population in millions\": \"12 millions\",\n",
      "        \"Migration\": 7679357,\n",
      "        \"Migration %\": \"63.75%\",\n",
      "        \"Immigration\": 50671,\n",
      "        \"Immigration %\": \"0.42%\"\n",
      "    },\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Year\": 1995,\n",
      "        \"Population\": 17065836,\n",
      "        \"Population dots\": 17,\n",
      "        \"Population in millions\": \"17 millions\",\n",
      "        \"Migration\": 4346546,\n",
      "        \"Migration %\": \"25.47%\",\n",
      "        \"Immigration\": 55794,\n",
      "        \"Immigration %\": \"0.33%\"\n",
      "    },\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Year\": 2000,\n",
      "        \"Population\": 20130334,\n",
      "        \"Population dots\": 20,\n",
      "        \"Population in millions\": \"20 millions\",\n",
      "        \"Migration\": 4749865,\n",
      "        \"Migration %\": \"23.6%\",\n",
      "        \"Immigration\": 60918,\n",
      "        \"Immigration %\": \"0.3%\"\n",
      "    },\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Year\": 2005,\n",
      "        \"Population\": 24404574,\n",
      "        \"Population dots\": 24,\n",
      "        \"Population in millions\": \"24 millions\",\n",
      "        \"Migration\": 4113962,\n",
      "        \"Migration %\": \"16.86%\",\n",
      "        \"Immigration\": 67045,\n",
      "        \"Immigration %\": \"0.27%\"\n",
      "    },\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Year\": 2010,\n",
      "        \"Population\": 28284088,\n",
      "        \"Population dots\": 28,\n",
      "        \"Population in millions\": \"28 millions\",\n",
      "        \"Migration\": 5263310,\n",
      "        \"Migration %\": \"18.61%\",\n",
      "        \"Immigration\": 73174,\n",
      "        \"Immigration %\": \"0.26%\"\n",
      "    }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/1888652294.py:188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  geojson_df[\"id\"] = geojson_df[\"id\"].str.strip().str.lower()\n",
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/1888652294.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  geojson_df[\"name\"] = geojson_df[\"name\"].str.strip().str.lower()\n"
     ]
    }
   ],
   "source": [
    "def process_excel_with_geojson(excel_path, sheet_name, geojson_path):\n",
    "    \"\"\"\n",
    "    Processes an Excel file to align its data with a GeoJSON file and filter matches.\n",
    "\n",
    "    Parameters:\n",
    "        excel_path (str): Path to the Excel file.\n",
    "        sheet_name (str): Name of the sheet to read from the Excel file.\n",
    "        geojson_path (str): Path to the GeoJSON file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: The processed and filtered DataFrame.\n",
    "            - list: Non-matching GeoJSON countries.\n",
    "    \"\"\"\n",
    "    # Step 1: Load GeoJSON and extract country names\n",
    "    geo_data = gpd.read_file(geojson_path)\n",
    "    geojson_countries = [country.strip().lower() for country in geo_data['name'].tolist()]\n",
    "\n",
    "    # Step 2: Load the specific sheet from Excel and process starting from row 11\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name, skiprows=10)\n",
    "\n",
    "    # Step 3: Keep and rename relevant columns\n",
    "    columns_to_keep = {\n",
    "        'Region, development group, country or area of destination': 'destination',\n",
    "        'Region, development group, country or area of origin': 'origin',\n",
    "        1990: '1990',\n",
    "        1995: '1995',\n",
    "        2000: '2000',\n",
    "        2005: '2005',\n",
    "        2010: '2010',\n",
    "        2015: '2015',\n",
    "        2020: '2020',\n",
    "        '1990.1': '1990.1',\n",
    "        '1995.1': '1995.1',\n",
    "        '2000.1': '2000.1',\n",
    "        '2005.1': '2005.1',\n",
    "        '2010.1': '2010.1',\n",
    "        '2015.1': '2015.1',\n",
    "        '2020.1': '2020.1',\n",
    "        '1990.2': '1990.2',\n",
    "        '1995.2': '1995.2',\n",
    "        '2000.2': '2000.2',\n",
    "        '2005.2': '2005.2',\n",
    "        '2010.2': '2010.2',\n",
    "        '2015.2': '2015.2',\n",
    "        '2020.2': '2020.2',\n",
    "    }\n",
    "    df = df[list(columns_to_keep.keys())].rename(columns=columns_to_keep)\n",
    "\n",
    "    # Step 4: Remove rows with NaN or 0 values in year columns\n",
    "    year_columns = [\n",
    "        '1990', '1995', '2000', '2005', '2010', '2015', '2020',\n",
    "        '1990.1', '1995.1', '2000.1', '2005.1', '2010.1', '2015.1', '2020.1',\n",
    "        '1990.2', '1995.2', '2000.2', '2005.2', '2010.2', '2015.2', '2020.2'\n",
    "    ]\n",
    "    df = df.dropna(subset=year_columns)\n",
    "    df = df[~(df[year_columns] == 0).any(axis=1)]\n",
    "\n",
    "    # Step 5: Align names in the DataFrame with GeoJSON using equivalences\n",
    "    equivalences = {\n",
    "        \"   Australia*\": \"australia\",\n",
    "        \"   Azerbaijan*\": \"azerbaijan\",\n",
    "        \"   Bahamas\": \"the bahamas\",\n",
    "        \"   Bolivia (Plurinational State of)\": \"bolivia\",\n",
    "        \"   Brunei Darussalam\": \"brunei\",\n",
    "        \"   China*\": \"china\",\n",
    "        \"   China, Taiwan Province of China*\": \"taiwan\",\n",
    "        \"   Congo\": \"republic of the congo\",\n",
    "        \"   Côte d'Ivoire\": \"ivory coast\",\n",
    "        \"   Cyprus*\": \"cyprus\",\n",
    "        \"   Czechia\": \"czech republic\",\n",
    "        \"   Dem. People's Republic of Korea\": \"north korea\",\n",
    "        \"   Democratic Republic of the Congo\": \"democratic republic of the congo\",\n",
    "        \"   Denmark*\": \"denmark\",\n",
    "        \"   Eswatini\": \"swaziland\",\n",
    "        \"   Falkland Islands (Malvinas)*\": \"falkland islands\",\n",
    "        \"   Finland*\": \"finland\",\n",
    "        \"   France*\": \"france\",\n",
    "        \"   French Southern and Antarctic Lands\": \"french southern and antarctic lands\",\n",
    "        \"   Georgia*\": \"georgia\",\n",
    "        \"   Greenland*\": \"greenland\",\n",
    "        \"   Guinea-Bissau\": \"guinea bissau\",\n",
    "        \"   Iran (Islamic Republic of)\": \"iran\",\n",
    "        \"   Kosovo\": \"kosovo\",\n",
    "        \"   Lao People's Democratic Republic\": \"laos\",\n",
    "        \"   Malaysia*\": \"malaysia\",\n",
    "        \"   Netherlands*\": \"netherlands\",\n",
    "        \"   New Caledonia*\": \"new caledonia\",\n",
    "        \"   New Zealand*\": \"new zealand\",\n",
    "        \"   North Macedonia\": \"macedonia\",\n",
    "        \"   Northern Cyprus\": \"northern cyprus\",\n",
    "        \"   Norway*\": \"norway\",\n",
    "        \"   Puerto Rico*\": \"puerto rico\",\n",
    "        \"   Republic of Korea\": \"south korea\",\n",
    "        \"   Republic of Moldova*\": \"moldova\",\n",
    "        \"   Russian Federation\": \"russia\",\n",
    "        \"   Serbia*\": \"republic of serbia\",\n",
    "        \"   Somalia\": \"somalia\",\n",
    "        \"   Spain*\": \"spain\",\n",
    "        \"   State of Palestine*\": \"west bank\",\n",
    "        \"   Syrian Arab Republic\": \"syria\",\n",
    "        \"   The Bahamas\": \"the bahamas\",\n",
    "        \"   Timor-Leste\": \"east timor\",\n",
    "        \"   Ukraine*\": \"ukraine\",\n",
    "        \"   United Kingdom*\": \"england\",\n",
    "        \"   United Republic of Tanzania*\": \"united republic of tanzania\",\n",
    "        \"   United States of America*\": \"usa\",\n",
    "        \"   Venezuela (Bolivarian Republic of)\": \"venezuela\",\n",
    "        \"   Viet Nam\": \"vietnam\",\n",
    "    }\n",
    "\n",
    "\n",
    "    df['destination'] = df['destination'].replace(equivalences).str.strip().str.lower()\n",
    "    df['origin'] = df['origin'].replace(equivalences).str.strip().str.lower()\n",
    "\n",
    "    # Step 6: Find non-matching GeoJSON countries before filtering\n",
    "    all_countries_in_df = set(df['destination'].unique()) | set(df['origin'].unique())\n",
    "    non_matching_geojson_countries = [country for country in geojson_countries if country not in all_countries_in_df]\n",
    "\n",
    "    # Step 7: Filter rows where destination and origin match GeoJSON countries\n",
    "    df_filtered = df[\n",
    "        (df['destination'].isin(geojson_countries)) &\n",
    "        (df['origin'].isin(geojson_countries))\n",
    "    ]\n",
    "\n",
    "    return df_filtered, non_matching_geojson_countries\n",
    "\n",
    "def analyze_migration_data(processed_df):\n",
    "    \"\"\"\n",
    "    Analyzes migration data for total migration (by origin) and immigration (by destination).\n",
    "\n",
    "    Parameters:\n",
    "        processed_df (pd.DataFrame): The filtered migration DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Aggregated total migration (by origin) and immigration (by destination) by year.\n",
    "    \"\"\"\n",
    "    # Step 1: Melt the DataFrame to make it long-format (Year, Value)\n",
    "    year_columns = ['1990', '1995', '2000', '2005', '2010', '2015', '2020']\n",
    "    melted_df = processed_df.melt(\n",
    "        id_vars=['origin', 'destination'],\n",
    "        value_vars=year_columns,\n",
    "        var_name='Year',\n",
    "        value_name='Migration'\n",
    "    )\n",
    "\n",
    "    # Step 2: Group by origin and year to calculate total migration\n",
    "    total_by_origin_year = melted_df.groupby(['origin', 'Year'])['Migration'].sum().reset_index()\n",
    "    total_by_origin_year = total_by_origin_year.rename(columns={'origin': 'Country', 'Migration': 'Migration'})\n",
    "\n",
    "    # Step 3: Group by destination and year to calculate total immigration\n",
    "    total_by_destination_year = melted_df.groupby(['destination', 'Year'])['Migration'].sum().reset_index()\n",
    "    total_by_destination_year = total_by_destination_year.rename(columns={'destination': 'Country', 'Migration': 'Immigration'})\n",
    "\n",
    "    # Step 4: Merge the two results on Country and Year\n",
    "    combined_data = pd.merge(\n",
    "        total_by_origin_year,\n",
    "        total_by_destination_year,\n",
    "        on=['Country', 'Year'],\n",
    "        how='outer'\n",
    "    ).fillna(0)  # Fill missing values with 0\n",
    "    \n",
    "    # Step 5: Ensure Migration and Immigration columns are integers\n",
    "    combined_data['Migration'] = combined_data['Migration'].astype(int)\n",
    "    combined_data['Immigration'] = combined_data['Immigration'].astype(int)\n",
    "\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "def process_population_and_migration_with_geojson(\n",
    "    population_path, geojson_path, combined_data\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes population and migration data, matches them with a GeoJSON file,\n",
    "    and outputs a JSON structure with added migration, immigration, and percentages.\n",
    "\n",
    "    Parameters:\n",
    "        population_path (str): Path to the population CSV file.\n",
    "        geojson_path (str): Path to the GeoJSON file.\n",
    "        combined_data (pd.DataFrame): Processed DataFrame containing migration and immigration data.\n",
    "\n",
    "    Returns:\n",
    "        list: A JSON-like list of dictionaries containing population, migration, and immigration data.\n",
    "    \"\"\"\n",
    "    # Step 1: Load the GeoJSON file and extract IDs and names\n",
    "    geo_data = gpd.read_file(geojson_path)\n",
    "    geojson_df = geo_data[[\"name\", \"id\"]]  # Create a DataFrame with 'name' and 'id'\n",
    "    geojson_df[\"id\"] = geojson_df[\"id\"].str.strip().str.lower()\n",
    "    geojson_df[\"name\"] = geojson_df[\"name\"].str.strip().str.lower()\n",
    "\n",
    "    # Step 2: Load the population data\n",
    "    population_df = pd.read_csv(population_path)\n",
    "\n",
    "    # Step 3: Filter the years we need\n",
    "    years_to_keep = [\"1990\", \"1995\", \"2000\", \"2005\", \"2010\", \"2015\", \"2020\"]\n",
    "    population_df = population_df[population_df[\"Year\"].astype(str).isin(years_to_keep)]\n",
    "\n",
    "    # Step 4: Normalize the 'Code' column for matching\n",
    "    population_df[\"Code\"] = population_df[\"Code\"].str.strip().str.lower()\n",
    "    population_df[\"Entity\"] = population_df[\"Entity\"].str.strip().str.lower()\n",
    "    population_df[\"Year\"] = population_df[\"Year\"].astype(str)\n",
    "\n",
    "    # Step 5: Merge population data with GeoJSON data on 'Code' and 'id'\n",
    "    merged_population = population_df.merge(\n",
    "        geojson_df, left_on=\"Code\", right_on=\"id\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Step 6: Add 'Population dots' column\n",
    "    merged_population[\"Population dots\"] = (\n",
    "        merged_population[\"Population (historical)\"] // 1_000_000\n",
    "    ).astype(int)\n",
    "\n",
    "    # Step 7: Add 'Population in millions' column\n",
    "    merged_population[\"Population in millions\"] = (\n",
    "        merged_population[\"Population (historical)\"] / 1_000_000\n",
    "    ).apply(lambda x: f\"{int(x):,} millions\")\n",
    "\n",
    "    # Step 8: Normalize combined_data for migration and immigration\n",
    "    combined_data[\"Country\"] = combined_data[\"Country\"].str.strip().str.lower()\n",
    "    combined_data[\"Year\"] = combined_data[\"Year\"].astype(str)\n",
    "\n",
    "    # Step 9: Merge migration and immigration data with population data\n",
    "    final_merged = merged_population.merge(\n",
    "        combined_data,\n",
    "        left_on=[\"name\", \"Year\"],\n",
    "        right_on=[\"Country\", \"Year\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Step 10: Convert Migration and Immigration to integers\n",
    "    final_merged[\"Migration\"] = final_merged[\"Migration\"].fillna(0).astype(int)\n",
    "    final_merged[\"Immigration\"] = final_merged[\"Immigration\"].fillna(0).astype(int)\n",
    "\n",
    "    # Step 11: Add 'Migration %' and 'Immigration %' columns\n",
    "    final_merged[\"Migration %\"] = (\n",
    "        (final_merged[\"Migration\"] / final_merged[\"Population (historical)\"] * 100)\n",
    "        .round(2)\n",
    "        .astype(str)\n",
    "        + \"%\"\n",
    "    )\n",
    "    final_merged[\"Immigration %\"] = (\n",
    "        (final_merged[\"Immigration\"] / final_merged[\"Population (historical)\"] * 100)\n",
    "        .round(2)\n",
    "        .astype(str)\n",
    "        + \"%\"\n",
    "    )\n",
    "\n",
    "    # Step 12: Capitalize country names and handle \"USA\"\n",
    "    final_merged[\"name\"] = final_merged[\"name\"].str.title().replace(\"Usa\", \"USA\")\n",
    "    # Ensure Year is an integer\n",
    "    final_merged[\"Year\"] = final_merged[\"Year\"].astype(int)\n",
    "\n",
    "    # Step 13: Convert to JSON format\n",
    "    json_result = final_merged[\n",
    "        [\n",
    "            \"name\",\n",
    "            \"Year\",\n",
    "            \"Population (historical)\",\n",
    "            \"Population dots\",\n",
    "            \"Population in millions\",\n",
    "            \"Migration\",\n",
    "            \"Migration %\",\n",
    "            \"Immigration\",\n",
    "            \"Immigration %\",\n",
    "        ]\n",
    "    ].rename(\n",
    "        columns={\n",
    "            \"name\": \"Country\",\n",
    "            \"Year\": \"Year\",\n",
    "            \"Population (historical)\": \"Population\",\n",
    "            \"Population dots\": \"Population dots\",\n",
    "            \"Population in millions\": \"Population in millions\",\n",
    "            \"Migration\": \"Migration\",\n",
    "            \"Migration %\": \"Migration %\",\n",
    "            \"Immigration\": \"Immigration\",\n",
    "            \"Immigration %\": \"Immigration %\",\n",
    "        }\n",
    "    ).to_dict(orient=\"records\")\n",
    "\n",
    "    # Save JSON to a file\n",
    "    with open(\"population_migration_geojson.json\", \"w\") as json_file:\n",
    "        json.dump(json_result, json_file, indent=4)\n",
    "\n",
    "    return json_result\n",
    "\n",
    "\n",
    "# Example usage\n",
    "excel_path = \"undesa_pd_2020_ims_stock_by_sex_destination_and_origin.xlsx\"\n",
    "geojson_path = \"/Users/magdalenabarros/InteractiveViz/data/world.geojson\"\n",
    "population_path = \"population.csv\"\n",
    "sheet_name = \"Table 1\"\n",
    "\n",
    "# Process migration data\n",
    "processed_df, _ = process_excel_with_geojson(excel_path, sheet_name, geojson_path)\n",
    "combined_data = analyze_migration_data(processed_df)\n",
    "\n",
    "# Process population and combined migration data\n",
    "result_json = process_population_and_migration_with_geojson(population_path, geojson_path, combined_data)\n",
    "\n",
    "# Save the result\n",
    "with open(\"population_data.json\", \"w\") as json_file:\n",
    "    json.dump(result_json, json_file, indent=4)\n",
    "\n",
    "print(json.dumps(result_json[:5], indent=4))  # Display the first 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/3002146241.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  geojson_df['name'] = geojson_df['name'].str.strip().str.title()  # Capitalize each word\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Destination\": \"Pakistan\",\n",
      "        \"Year\": \"2010\",\n",
      "        \"Migration dots\": 19\n",
      "    },\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Destination\": \"Saudi Arabia\",\n",
      "        \"Year\": \"2005\",\n",
      "        \"Migration dots\": 2\n",
      "    },\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Destination\": \"Saudi Arabia\",\n",
      "        \"Year\": \"2000\",\n",
      "        \"Migration dots\": 1\n",
      "    },\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Destination\": \"Pakistan\",\n",
      "        \"Year\": \"1995\",\n",
      "        \"Migration dots\": 12\n",
      "    },\n",
      "    {\n",
      "        \"Country\": \"Afghanistan\",\n",
      "        \"Destination\": \"Turkey\",\n",
      "        \"Year\": \"2020\",\n",
      "        \"Migration dots\": 1\n",
      "    }\n",
      "]\n",
      "Number of unique countries matching the GeoJSON: 129\n",
      "Matched countries:\n",
      "['Albania', 'Haiti', 'Panama', 'Chile', 'Mozambique', 'Hungary', 'Uganda', 'Australia', 'Madagascar', 'South Sudan', 'Eritrea', 'Nicaragua', 'Bolivia', 'Romania', 'Germany', 'Greece', 'Cuba', 'Georgia', 'Republic Of Serbia', 'Italy', 'Jamaica', 'Iraq', 'Guyana', 'Slovakia', 'Bulgaria', 'Sierra Leone', 'Lithuania', 'Czech Republic', 'Indonesia', 'Suriname', 'Bosnia And Herzegovina', 'South Korea', 'Yemen', 'Thailand', 'Tajikistan', 'Zimbabwe', 'East Timor', 'Austria', 'Ethiopia', 'Netherlands', 'Israel', 'Philippines', 'Bangladesh', 'Sudan', 'Macedonia', 'Burkina Faso', 'England', 'Malawi', 'Nigeria', 'Pakistan', 'Mali', 'South Africa', 'Uzbekistan', 'Azerbaijan', 'Poland', 'Western Sahara', 'Switzerland', 'Paraguay', 'Honduras', 'El Salvador', 'Central African Republic', 'Ukraine', 'Ivory Coast', 'Russia', 'Sri Lanka', 'Chad', 'Japan', 'Trinidad And Tobago', 'West Bank', 'Brazil', 'Democratic Republic Of The Congo', 'Algeria', 'Egypt', 'Colombia', 'Canada', 'Kenya', 'Benin', 'Belgium', 'Armenia', 'Iran', 'Kazakhstan', 'Senegal', 'Lesotho', 'Malaysia', 'Ecuador', 'Vietnam', 'Turkmenistan', 'Somalia', 'China', 'Nepal', 'Angola', 'Myanmar', 'France', 'Syria', 'Spain', 'Morocco', 'Belarus', 'Ghana', 'Venezuela', 'Burundi', 'Uruguay', 'Dominican Republic', 'Liberia', 'Argentina', 'Cambodia', 'Puerto Rico', 'New Zealand', 'Laos', 'Rwanda', 'Peru', 'Kyrgyzstan', 'India', 'Moldova', 'Mexico', 'Tunisia', 'Finland', 'Turkey', 'Togo', 'Guinea', 'Latvia', 'Niger', 'Bhutan', 'Lebanon', 'Portugal', 'Croatia', 'Ireland', 'Jordan', 'Guatemala', 'Afghanistan']\n",
      "\n",
      "Unmatched countries:\n",
      "['Cyprus', 'Botswana', 'Equatorial Guinea', 'Kosovo', 'North Korea', 'Djibouti', 'Gambia', 'Cameroon', 'Montenegro', 'Qatar', 'Usa', 'United Republic Of Tanzania', 'Namibia', 'Mongolia', 'Estonia', 'Kuwait', 'Slovenia', 'Solomon Islands', 'Taiwan', 'Vanuatu', 'Gabon', 'Norway', 'Costa Rica', 'Guinea Bissau', 'Greenland', 'Northern Cyprus', 'Papua New Guinea', 'Zambia', 'Somaliland', 'Swaziland', 'Iceland', 'Fiji', 'Denmark', 'The Bahamas', 'Sweden', 'Libya', 'Saudi Arabia', 'Luxembourg', 'Brunei', 'Oman', 'French Southern And Antarctic Lands', 'Falkland Islands', 'United Arab Emirates', 'Mauritania', 'Republic Of The Congo', 'New Caledonia', 'Belize']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/3002146241.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[f\"{year} dots\"] = (df_filtered[year] // 100_000).astype(int)\n",
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/3002146241.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[f\"{year} dots\"] = (df_filtered[year] // 100_000).astype(int)\n",
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/3002146241.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[f\"{year} dots\"] = (df_filtered[year] // 100_000).astype(int)\n",
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/3002146241.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[f\"{year} dots\"] = (df_filtered[year] // 100_000).astype(int)\n",
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/3002146241.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[f\"{year} dots\"] = (df_filtered[year] // 100_000).astype(int)\n",
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/3002146241.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[f\"{year} dots\"] = (df_filtered[year] // 100_000).astype(int)\n",
      "/var/folders/w7/vh3676rs0zg6dygkkjljyn5c0000gn/T/ipykernel_16684/3002146241.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[f\"{year} dots\"] = (df_filtered[year] // 100_000).astype(int)\n"
     ]
    }
   ],
   "source": [
    "def process_excel_with_geojson_to_json(excel_path, sheet_name, geojson_path):\n",
    "    \"\"\"\n",
    "    Processes an Excel file, aligns its data with a GeoJSON file, and outputs a JSON structure\n",
    "    with migration dots for each year.\n",
    "\n",
    "    Parameters:\n",
    "        excel_path (str): Path to the Excel file.\n",
    "        sheet_name (str): Name of the sheet to read from the Excel file.\n",
    "        geojson_path (str): Path to the GeoJSON file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - list: JSON-like list of dictionaries with migration dots.\n",
    "            - int: Number of unique countries matching GeoJSON names.\n",
    "            - list: List of matched countries.\n",
    "            - list: List of unmatched countries.\n",
    "    \"\"\"\n",
    "    # Step 1: Load GeoJSON and extract country names\n",
    "    geo_data = gpd.read_file(geojson_path)\n",
    "    geojson_df = geo_data[['name']]  # Extract names\n",
    "    geojson_df['name'] = geojson_df['name'].str.strip().str.title()  # Capitalize each word\n",
    "\n",
    "    geojson_countries = geojson_df['name'].tolist()\n",
    "\n",
    "    # Step 2: Load the specific sheet from Excel and process starting from row 11\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name, skiprows=10)\n",
    "\n",
    "    # Step 3: Keep and rename relevant columns\n",
    "    columns_to_keep = {\n",
    "        \"Region, development group, country or area of destination\": \"destination\",\n",
    "        \"Region, development group, country or area of origin\": \"origin\",\n",
    "        1990: \"1990\",\n",
    "        1995: \"1995\",\n",
    "        2000: \"2000\",\n",
    "        2005: \"2005\",\n",
    "        2010: \"2010\",\n",
    "        2015: \"2015\",\n",
    "        2020: \"2020\",\n",
    "    }\n",
    "    df = df[list(columns_to_keep.keys())].rename(columns=columns_to_keep)\n",
    "\n",
    "    # Step 4: Remove rows with NaN or 0 values in year columns\n",
    "    year_columns = [\"1990\", \"1995\", \"2000\", \"2005\", \"2010\", \"2015\", \"2020\"]\n",
    "    df = df.dropna(subset=year_columns)\n",
    "    df = df[~(df[year_columns] == 0).any(axis=1)]\n",
    "\n",
    "    # Step 5: Align names in the DataFrame with GeoJSON using equivalences\n",
    "    equivalences = {\n",
    "        \"   Australia*\": \"australia\",\n",
    "        \"   Azerbaijan*\": \"azerbaijan\",\n",
    "        \"   Bahamas\": \"the bahamas\",\n",
    "        \"   Bolivia (Plurinational State of)\": \"bolivia\",\n",
    "        \"   Brunei Darussalam\": \"brunei\",\n",
    "        \"   China*\": \"china\",\n",
    "        \"   China, Taiwan Province of China*\": \"taiwan\",\n",
    "        \"   Congo\": \"republic of the congo\",\n",
    "        \"   Côte d'Ivoire\": \"ivory coast\",\n",
    "        \"   Cyprus*\": \"cyprus\",\n",
    "        \"   Czechia\": \"czech republic\",\n",
    "        \"   Dem. People's Republic of Korea\": \"north korea\",\n",
    "        \"   Democratic Republic of the Congo\": \"democratic republic of the congo\",\n",
    "        \"   Denmark*\": \"denmark\",\n",
    "        \"   Eswatini\": \"swaziland\",\n",
    "        \"   Falkland Islands (Malvinas)*\": \"falkland islands\",\n",
    "        \"   Finland*\": \"finland\",\n",
    "        \"   France*\": \"france\",\n",
    "        \"   French Southern and Antarctic Lands\": \"french southern and antarctic lands\",\n",
    "        \"   Georgia*\": \"georgia\",\n",
    "        \"   Greenland*\": \"greenland\",\n",
    "        \"   Guinea-Bissau\": \"guinea bissau\",\n",
    "        \"   Iran (Islamic Republic of)\": \"iran\",\n",
    "        \"   Kosovo\": \"kosovo\",\n",
    "        \"   Lao People's Democratic Republic\": \"laos\",\n",
    "        \"   Malaysia*\": \"malaysia\",\n",
    "        \"   Netherlands*\": \"netherlands\",\n",
    "        \"   New Caledonia*\": \"new caledonia\",\n",
    "        \"   New Zealand*\": \"new zealand\",\n",
    "        \"   North Macedonia\": \"macedonia\",\n",
    "        \"   Northern Cyprus\": \"northern cyprus\",\n",
    "        \"   Norway*\": \"norway\",\n",
    "        \"   Puerto Rico*\": \"puerto rico\",\n",
    "        \"   Republic of Korea\": \"south korea\",\n",
    "        \"   Republic of Moldova*\": \"moldova\",\n",
    "        \"   Russian Federation\": \"russia\",\n",
    "        \"   Serbia*\": \"republic of serbia\",\n",
    "        \"   Somalia\": \"somalia\",\n",
    "        \"   Spain*\": \"spain\",\n",
    "        \"   State of Palestine*\": \"west bank\",\n",
    "        \"   Syrian Arab Republic\": \"syria\",\n",
    "        \"   The Bahamas\": \"the bahamas\",\n",
    "        \"   Timor-Leste\": \"east timor\",\n",
    "        \"   Ukraine*\": \"ukraine\",\n",
    "        \"   United Kingdom*\": \"england\",\n",
    "        \"   United Republic of Tanzania*\": \"united republic of tanzania\",\n",
    "        \"   United States of America*\": \"usa\",\n",
    "        \"   Venezuela (Bolivarian Republic of)\": \"venezuela\",\n",
    "        \"   Viet Nam\": \"vietnam\",\n",
    "    }\n",
    "\n",
    "    df[\"destination\"] = (\n",
    "        df[\"destination\"]\n",
    "        .replace(equivalences)\n",
    "        .str.strip()\n",
    "        .str.title()  # Capitalize each word\n",
    "    )\n",
    "    df[\"origin\"] = (\n",
    "        df[\"origin\"]\n",
    "        .replace(equivalences)\n",
    "        .str.strip()\n",
    "        .str.title()  # Capitalize each word\n",
    "    )\n",
    "\n",
    "    # Step 6: Filter rows where destination and origin match GeoJSON countries\n",
    "    df_filtered = df[\n",
    "        (df[\"destination\"].isin(geojson_countries))\n",
    "        & (df[\"origin\"].isin(geojson_countries))\n",
    "    ]\n",
    "\n",
    "    # Step 7: Create new columns for \"migration dots\" by dividing values by 100,000 and truncating\n",
    "    for year in year_columns:\n",
    "        df_filtered[f\"{year} dots\"] = (df_filtered[year] // 100_000).astype(int)\n",
    "\n",
    "    # Step 8: Remove rows where all \"migration dots\" columns are zeros\n",
    "    dot_columns = [f\"{year} dots\" for year in year_columns]\n",
    "    mask = (df_filtered[dot_columns] != 0).any(axis=1)\n",
    "    df_filtered = df_filtered[mask]\n",
    "\n",
    "    # Step 9: Melt the DataFrame to prepare for JSON export\n",
    "    melted_df = df_filtered.melt(\n",
    "        id_vars=[\"origin\", \"destination\"],\n",
    "        value_vars=dot_columns,\n",
    "        var_name=\"Year\",\n",
    "        value_name=\"Migration dots\",\n",
    "    )\n",
    "\n",
    "    # Extract the year from the \"Year dots\" column\n",
    "    melted_df[\"Year\"] = melted_df[\"Year\"].str.replace(\" dots\", \"\")\n",
    "\n",
    "    # Step 10: Remove rows with zero \"Migration dots\"\n",
    "    melted_df = melted_df[melted_df[\"Migration dots\"] > 0]\n",
    "\n",
    "    # Step 11: Convert \"Usa\" to \"USA\" only for JSON export\n",
    "    melted_df[\"origin\"] = melted_df[\"origin\"].replace({\"Usa\": \"USA\"})\n",
    "    melted_df[\"destination\"] = melted_df[\"destination\"].replace({\"Usa\": \"USA\"})\n",
    "\n",
    "    # Count matched and unmatched countries\n",
    "    matched_countries = set(melted_df[\"origin\"]).intersection(set(geojson_countries))\n",
    "    unmatched_countries = set(geojson_countries) - set(melted_df[\"origin\"])\n",
    "\n",
    "    # Step 12: Convert to JSON format\n",
    "    json_result = melted_df.rename(\n",
    "        columns={\n",
    "            \"origin\": \"Country\",\n",
    "            \"destination\": \"Destination\",\n",
    "            \"Year\": \"Year\",\n",
    "            \"Migration dots\": \"Migration dots\",\n",
    "        }\n",
    "    ).sort_values(by=\"Country\").to_dict(orient=\"records\")\n",
    "\n",
    "    return json_result, len(matched_countries), list(matched_countries), list(unmatched_countries)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "excel_path = \"undesa_pd_2020_ims_stock_by_sex_destination_and_origin.xlsx\"\n",
    "sheet_name = \"Table 1\"\n",
    "geojson_path = \"/Users/magdalenabarros/InteractiveViz/data/world.geojson\"\n",
    "\n",
    "# Process the Excel data with the GeoJSON and convert to JSON\n",
    "result_json, matched_count, matched_countries, unmatched_countries = process_excel_with_geojson_to_json(\n",
    "    excel_path, sheet_name, geojson_path\n",
    ")\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"migration.json\", \"w\") as json_file:\n",
    "    json.dump(result_json, json_file, indent=4)\n",
    "\n",
    "# Display the JSON structure\n",
    "print(json.dumps(result_json[:5], indent=4))  # Print the first 5 records for inspection\n",
    "\n",
    "# Display match results\n",
    "print(f\"Number of unique countries matching the GeoJSON: {matched_count}\")\n",
    "print(\"Matched countries:\")\n",
    "print(matched_countries)\n",
    "print(\"\\nUnmatched countries:\")\n",
    "print(unmatched_countries)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
